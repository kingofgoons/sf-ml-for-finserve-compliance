{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 - ML + LLM Integration: The Optimal Architecture\n",
        "\n",
        "## Combining Fast ML with Intelligent LLM Analysis\n",
        "\n",
        "**Goal:** Build a tiered architecture that uses ML as a fast filter and Claude claude-opus-4-5 for deep analysis.\n",
        "\n",
        "### The Problem with Single-Approach Solutions\n",
        "\n",
        "| Approach | Pros | Cons |\n",
        "|----------|------|------|\n",
        "| **ML Only** | Fast, cheap, scalable | Misses nuanced violations |\n",
        "| **LLM Only** | Understands context, reasoning | Expensive at scale, slower |\n",
        "\n",
        "### The Optimal Architecture\n",
        "\n",
        "```\n",
        "10,000 emails/day\n",
        "       â”‚\n",
        "       â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚ ML Classifier   â”‚  â† Fast, cheap (~$0.001/email)\n",
        "â”‚ (XGBoost)       â”‚  â† 5ms latency\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "         â”‚\n",
        "   â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”\n",
        "   â”‚           â”‚\n",
        " 8,500      1,500 \n",
        " CLEAN      flagged\n",
        "              â”‚\n",
        "              â–¼\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚ Claude claude-opus-4-5    â”‚  â† Smart, reasoning (~$0.01/email)\n",
        "â”‚ Deep Analysis   â”‚  â† 200ms latency\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "         â”‚\n",
        "   â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”\n",
        "   â”‚           â”‚\n",
        " 1,200       300 \n",
        " Low Risk   HIGH RISK â†’ Human Review\n",
        "```\n",
        "\n",
        "**Result:** 90% cost reduction vs all-LLM, while maintaining accuracy on hard cases.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "from snowflake.snowpark import Session\n",
        "\n",
        "session = Session.builder.getOrCreate()\n",
        "session.use_warehouse(\"COMPLIANCE_DEMO_WH\")\n",
        "session.use_database(\"COMPLIANCE_DEMO\")\n",
        "session.use_schema(\"ML\")\n",
        "\n",
        "print(f\"Connected as: {session.get_current_user()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load ML Predictions\n",
        "\n",
        "Start with the predictions from our XGBoost model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load ML predictions\n",
        "print(\"--- ML Model Predictions Summary ---\")\n",
        "session.sql(\"\"\"\n",
        "    SELECT \n",
        "        PREDICTED_VIOLATION,\n",
        "        COUNT(*) as COUNT,\n",
        "        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1) as PCT\n",
        "    FROM COMPLIANCE_DEMO.ML.MODEL_PREDICTIONS_V1\n",
        "    GROUP BY 1\n",
        "    ORDER BY 1\n",
        "\"\"\").show()\n",
        "\n",
        "# How many did ML flag?\n",
        "flagged_count = session.sql(\"\"\"\n",
        "    SELECT COUNT(*) FROM COMPLIANCE_DEMO.ML.MODEL_PREDICTIONS_V1 WHERE PREDICTED_VIOLATION = 1\n",
        "\"\"\").collect()[0][0]\n",
        "print(f\"\\nML flagged {flagged_count:,} emails for deeper review\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Apply Claude claude-opus-4-5 to ML-Flagged Emails\n",
        "\n",
        "Only run the expensive LLM on emails the ML model flagged as suspicious."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run Claude claude-opus-4-5 analysis on ML-flagged emails (sample for demo speed)\n",
        "print(\"ğŸ¤– Running Claude claude-opus-4-5 on ML-flagged emails...\")\n",
        "\n",
        "session.sql(\"\"\"\n",
        "CREATE OR REPLACE TABLE COMPLIANCE_DEMO.ML.LLM_ANALYSIS AS\n",
        "WITH flagged_emails AS (\n",
        "    SELECT \n",
        "        p.EMAIL_ID,\n",
        "        p.COMPLIANCE_LABEL as ACTUAL_LABEL,\n",
        "        p.PREDICTED_VIOLATION as ML_PREDICTION,\n",
        "        e.SUBJECT,\n",
        "        e.BODY\n",
        "    FROM COMPLIANCE_DEMO.ML.MODEL_PREDICTIONS_V1 p\n",
        "    JOIN COMPLIANCE_DEMO.EMAIL_SURVEILLANCE.EMAILS e ON p.EMAIL_ID = e.EMAIL_ID\n",
        "    WHERE p.PREDICTED_VIOLATION = 1\n",
        "    LIMIT 50  -- Sample for demo speed\n",
        ")\n",
        "SELECT \n",
        "    EMAIL_ID,\n",
        "    ACTUAL_LABEL,\n",
        "    ML_PREDICTION,\n",
        "    SUBJECT,\n",
        "    \n",
        "    -- Claude claude-opus-4-5 classification\n",
        "    SNOWFLAKE.CORTEX.COMPLETE(\n",
        "        'claude-opus-4-5',\n",
        "        CONCAT(\n",
        "            'You are a hedge fund compliance analyst. Analyze this email and determine if it contains a compliance violation. ',\n",
        "            'Respond with ONLY a JSON object: {\"is_violation\": true/false, \"confidence\": 0.0-1.0, \"category\": \"INSIDER_TRADING|CONFIDENTIALITY|PERSONAL_TRADING|INFO_BARRIER|CLEAN\", \"reasoning\": \"brief explanation\"}. ',\n",
        "            'Email subject: ', SUBJECT, ' ',\n",
        "            'Email body: ', LEFT(BODY, 1500)\n",
        "        )\n",
        "    ) AS CLAUDE_ANALYSIS\n",
        "    \n",
        "FROM flagged_emails\n",
        "\"\"\").collect()\n",
        "\n",
        "print(\"âœ… Claude analysis complete\")\n",
        "\n",
        "# Preview results\n",
        "session.sql(\"SELECT EMAIL_ID, ACTUAL_LABEL, CLAUDE_ANALYSIS FROM COMPLIANCE_DEMO.ML.LLM_ANALYSIS LIMIT 5\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Compare ML vs Claude Performance\n",
        "\n",
        "See how the two methods complement each other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parse Claude's JSON response and compare\n",
        "print(\"--- ML vs Claude Comparison ---\")\n",
        "\n",
        "session.sql(\"\"\"\n",
        "    SELECT \n",
        "        ACTUAL_LABEL,\n",
        "        ML_PREDICTION,\n",
        "        TRY_PARSE_JSON(CLAUDE_ANALYSIS):is_violation::BOOLEAN as CLAUDE_VIOLATION,\n",
        "        TRY_PARSE_JSON(CLAUDE_ANALYSIS):category::STRING as CLAUDE_CATEGORY,\n",
        "        TRY_PARSE_JSON(CLAUDE_ANALYSIS):confidence::FLOAT as CLAUDE_CONFIDENCE,\n",
        "        LEFT(TRY_PARSE_JSON(CLAUDE_ANALYSIS):reasoning::STRING, 100) as REASONING\n",
        "    FROM COMPLIANCE_DEMO.ML.LLM_ANALYSIS\n",
        "    LIMIT 10\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create Ensemble Predictions\n",
        "\n",
        "Combine ML and LLM for maximum accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create ensemble predictions view\n",
        "session.sql(\"\"\"\n",
        "CREATE OR REPLACE VIEW COMPLIANCE_DEMO.ML.ENSEMBLE_RESULTS AS\n",
        "SELECT \n",
        "    EMAIL_ID,\n",
        "    ACTUAL_LABEL,\n",
        "    CASE WHEN ACTUAL_LABEL != 'CLEAN' THEN 1 ELSE 0 END as ACTUAL_VIOLATION,\n",
        "    ML_PREDICTION,\n",
        "    COALESCE(TRY_PARSE_JSON(CLAUDE_ANALYSIS):is_violation::BOOLEAN, FALSE) as CLAUDE_VIOLATION,\n",
        "    TRY_PARSE_JSON(CLAUDE_ANALYSIS):confidence::FLOAT as CLAUDE_CONFIDENCE,\n",
        "    TRY_PARSE_JSON(CLAUDE_ANALYSIS):category::STRING as CLAUDE_CATEGORY,\n",
        "    \n",
        "    -- Ensemble: High precision (both agree it's a violation)\n",
        "    CASE WHEN ML_PREDICTION = 1 AND TRY_PARSE_JSON(CLAUDE_ANALYSIS):is_violation::BOOLEAN = TRUE \n",
        "         THEN 1 ELSE 0 END as ENSEMBLE_HIGH_PRECISION,\n",
        "    \n",
        "    -- Priority score for human review\n",
        "    CASE \n",
        "        WHEN ML_PREDICTION = 1 AND TRY_PARSE_JSON(CLAUDE_ANALYSIS):is_violation::BOOLEAN = TRUE \n",
        "            AND TRY_PARSE_JSON(CLAUDE_ANALYSIS):confidence::FLOAT > 0.8\n",
        "        THEN 'CRITICAL'\n",
        "        WHEN ML_PREDICTION = 1 AND TRY_PARSE_JSON(CLAUDE_ANALYSIS):is_violation::BOOLEAN = TRUE\n",
        "        THEN 'HIGH'\n",
        "        WHEN ML_PREDICTION = 1\n",
        "        THEN 'MEDIUM'\n",
        "        ELSE 'LOW'\n",
        "    END as REVIEW_PRIORITY\n",
        "    \n",
        "FROM COMPLIANCE_DEMO.ML.LLM_ANALYSIS\n",
        "\"\"\").collect()\n",
        "\n",
        "print(\"âœ… Created ensemble results view\")\n",
        "\n",
        "# Show priority breakdown\n",
        "print(\"\\n--- Review Priority Distribution ---\")\n",
        "session.sql(\"\"\"\n",
        "    SELECT \n",
        "        REVIEW_PRIORITY,\n",
        "        COUNT(*) as COUNT\n",
        "    FROM COMPLIANCE_DEMO.ML.ENSEMBLE_RESULTS\n",
        "    GROUP BY 1\n",
        "    ORDER BY \n",
        "        CASE REVIEW_PRIORITY\n",
        "            WHEN 'CRITICAL' THEN 1\n",
        "            WHEN 'HIGH' THEN 2\n",
        "            WHEN 'MEDIUM' THEN 3\n",
        "            ELSE 4\n",
        "        END\n",
        "\"\"\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Cost Analysis\n",
        "\n",
        "Compare the cost of different approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cost comparison (estimated)\n",
        "total_emails = 10000\n",
        "ml_flagged = flagged_count\n",
        "\n",
        "# Estimated costs per email (approximate)\n",
        "ml_cost_per_email = 0.0001  # ~$0.0001 per email for XGBoost inference\n",
        "llm_cost_per_email = 0.01   # ~$0.01 per email for Claude claude-opus-4-5\n",
        "\n",
        "# Calculate costs for different approaches\n",
        "all_llm_cost = total_emails * llm_cost_per_email\n",
        "all_ml_cost = total_emails * ml_cost_per_email\n",
        "tiered_cost = (total_emails * ml_cost_per_email) + (ml_flagged * llm_cost_per_email)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"COST ANALYSIS: 10,000 EMAILS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\"\"\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚  APPROACH 1: All LLM (Claude claude-opus-4-5 on every email)        â”‚\n",
        "â”‚  â””â”€â”€ Cost: ${all_llm_cost:,.2f}                                    â”‚\n",
        "â”‚  â””â”€â”€ LLM calls: {total_emails:,}                                 â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚  APPROACH 2: All ML (XGBoost only)                         â”‚\n",
        "â”‚  â””â”€â”€ Cost: ${all_ml_cost:,.2f}                                     â”‚\n",
        "â”‚  â””â”€â”€ Limitation: May miss nuanced violations               â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚  APPROACH 3: TIERED (ML filter â†’ LLM on flagged)           â”‚\n",
        "â”‚  â””â”€â”€ Cost: ${tiered_cost:,.2f}                                     â”‚\n",
        "â”‚  â””â”€â”€ ML scans: {total_emails:,}, LLM deep-dives: {ml_flagged:,}      â”‚\n",
        "â”‚  â””â”€â”€ SAVINGS vs All-LLM: {(1 - tiered_cost/all_llm_cost)*100:.0f}%                          â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "**What we demonstrated:**\n",
        "- ML as a fast, cheap filter (classifies all 10K emails in seconds)\n",
        "- Claude claude-opus-4-5 for deep analysis (only on ML-flagged emails)\n",
        "- Ensemble approach combining both for maximum accuracy\n",
        "- Priority scoring for human review queue\n",
        "\n",
        "**Key Benefits of Tiered Architecture:**\n",
        "1. **Cost Efficiency:** 80-90% reduction vs all-LLM\n",
        "2. **Speed:** Instant ML classification, targeted LLM analysis\n",
        "3. **Accuracy:** ML catches obvious cases, LLM handles nuance\n",
        "4. **Explainability:** Claude provides reasoning for each decision\n",
        "\n",
        "**Next:** In notebook 05, we'll fine-tune an LLM specifically for compliance classification."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
