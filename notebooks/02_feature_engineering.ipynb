{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 - Feature Engineering with Feature Store\n",
        "\n",
        "## Building Reusable Compliance Risk Features\n",
        "\n",
        "**Goal:** Use Snowflake's Feature Store to create reusable, versioned features for compliance risk detection.\n",
        "\n",
        "### What is a Feature Store?\n",
        "\n",
        "A Feature Store is a centralized repository for ML features. It provides:\n",
        "- **Reusability:** Define features once, use across multiple models\n",
        "- **Versioning:** Track feature changes over time\n",
        "- **Consistency:** Same feature logic for training and inference\n",
        "- **Point-in-time correctness:** Generate training data without data leakage\n",
        "\n",
        "### Features We'll Build\n",
        "\n",
        "| Feature | Description | Risk Signal |\n",
        "|---------|-------------|-------------|\n",
        "| `cross_dept_ratio` | % of emails sent to other departments | High cross-dept = potential leaks |\n",
        "| `after_hours_ratio` | % of emails sent outside business hours | Unusual activity pattern |\n",
        "| `urgency_score` | Count of urgent keywords | High urgency = suspicious |\n",
        "| `secrecy_score` | Count of secrecy keywords | Explicit secrecy = red flag |\n",
        "| `barrier_crossing` | Research↔Trading emails | Information barrier risk |\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "from snowflake.snowpark import Session\n",
        "from snowflake.snowpark.functions import col, count, avg, sum as sum_, when, hour, length, lit\n",
        "from snowflake.ml.feature_store import FeatureStore, Entity, FeatureView\n",
        "\n",
        "session = Session.builder.getOrCreate()\n",
        "session.use_warehouse(\"COMPLIANCE_DEMO_WH\")\n",
        "session.use_database(\"COMPLIANCE_DEMO\")\n",
        "session.use_schema(\"ML\")\n",
        "\n",
        "print(f\"Connected as: {session.get_current_user()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Initialize Feature Store\n",
        "\n",
        "The Feature Store uses a schema to store metadata about entities and features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Feature Store\n",
        "fs = FeatureStore(\n",
        "    session=session,\n",
        "    database=\"COMPLIANCE_DEMO\",\n",
        "    name=\"ML\",  # Schema name\n",
        "    default_warehouse=\"COMPLIANCE_DEMO_WH\",\n",
        ")\n",
        "print(\"✅ Feature Store initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Define Entities\n",
        "\n",
        "Entities are the \"join keys\" for features - the business objects we're building features for. We'll create an EMAIL entity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Email entity\n",
        "email_entity = Entity(\n",
        "    name=\"EMAIL\",\n",
        "    join_keys=[\"EMAIL_ID\"],\n",
        "    desc=\"Individual email message for compliance analysis\"\n",
        ")\n",
        "\n",
        "fs.register_entity(email_entity)\n",
        "print(\"✅ Registered entity: EMAIL\")\n",
        "\n",
        "# List all entities\n",
        "fs.list_entities().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Compute Features\n",
        "\n",
        "Now we'll compute compliance risk features from the raw email data. These features capture patterns we identified in data exploration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First, create UDFs for text-based features\n",
        "# These run inside Snowflake - no data movement\n",
        "\n",
        "session.sql(\"\"\"\n",
        "CREATE OR REPLACE FUNCTION COMPLIANCE_DEMO.ML.DETECT_URGENCY(text STRING)\n",
        "RETURNS INT\n",
        "LANGUAGE PYTHON\n",
        "RUNTIME_VERSION = '3.11'\n",
        "HANDLER = 'detect_urgency'\n",
        "AS $$\n",
        "def detect_urgency(text: str) -> int:\n",
        "    '''Return urgency score based on keyword presence (0-5).'''\n",
        "    if text is None:\n",
        "        return 0\n",
        "    text_upper = text.upper()\n",
        "    urgency_keywords = [\"URGENT\", \"ASAP\", \"IMMEDIATELY\", \"TIME SENSITIVE\", \"ACT NOW\", \"ACT FAST\"]\n",
        "    return sum(1 for kw in urgency_keywords if kw in text_upper)\n",
        "$$\n",
        "\"\"\").collect()\n",
        "\n",
        "session.sql(\"\"\"\n",
        "CREATE OR REPLACE FUNCTION COMPLIANCE_DEMO.ML.DETECT_SECRECY(text STRING)\n",
        "RETURNS INT\n",
        "LANGUAGE PYTHON\n",
        "RUNTIME_VERSION = '3.11'\n",
        "HANDLER = 'detect_secrecy'\n",
        "AS $$\n",
        "def detect_secrecy(text: str) -> int:\n",
        "    '''Return secrecy score based on suspicious phrases (0-6).'''\n",
        "    if text is None:\n",
        "        return 0\n",
        "    text_upper = text.upper()\n",
        "    secrecy_phrases = [\n",
        "        \"DELETE\", \"DON'T TELL\", \"KEEP THIS BETWEEN\", \n",
        "        \"OFF THE RECORD\", \"CONFIDENTIAL\", \"SECRET\"\n",
        "    ]\n",
        "    return sum(1 for phrase in secrecy_phrases if phrase in text_upper)\n",
        "$$\n",
        "\"\"\").collect()\n",
        "\n",
        "print(\"✅ Created UDFs: DETECT_URGENCY, DETECT_SECRECY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute all features using SQL (cleaner than Snowpark for complex logic)\n",
        "email_features_df = session.sql(\"\"\"\n",
        "    SELECT \n",
        "        EMAIL_ID,\n",
        "        COMPLIANCE_LABEL,\n",
        "        \n",
        "        -- Text-based features using our UDFs\n",
        "        COMPLIANCE_DEMO.ML.DETECT_URGENCY(BODY) AS URGENCY_SCORE,\n",
        "        COMPLIANCE_DEMO.ML.DETECT_SECRECY(BODY) AS SECRECY_SCORE,\n",
        "        COMPLIANCE_DEMO.ML.DETECT_URGENCY(BODY) + COMPLIANCE_DEMO.ML.DETECT_SECRECY(BODY) AS TOTAL_RISK_SCORE,\n",
        "        \n",
        "        -- Structural features\n",
        "        LENGTH(BODY) AS BODY_LENGTH,\n",
        "        \n",
        "        -- Cross-department indicator\n",
        "        CASE WHEN SENDER_DEPT != RECIPIENT_DEPT THEN 1 ELSE 0 END AS IS_CROSS_DEPT,\n",
        "        \n",
        "        -- Information barrier crossing (Research <-> Trading)\n",
        "        CASE \n",
        "            WHEN (SENDER_DEPT = 'Research' AND RECIPIENT_DEPT = 'Trading')\n",
        "              OR (SENDER_DEPT = 'Trading' AND RECIPIENT_DEPT = 'Research')\n",
        "            THEN 1 ELSE 0 \n",
        "        END AS IS_BARRIER_CROSSING,\n",
        "        \n",
        "        -- After-hours indicator\n",
        "        CASE \n",
        "            WHEN HOUR(SENT_AT) < 8 OR HOUR(SENT_AT) >= 18 \n",
        "            THEN 1 ELSE 0 \n",
        "        END AS IS_AFTER_HOURS\n",
        "        \n",
        "    FROM COMPLIANCE_DEMO.EMAIL_SURVEILLANCE.EMAILS\n",
        "\"\"\")\n",
        "\n",
        "print(\"--- Feature Preview ---\")\n",
        "email_features_df.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Save and Register Feature View\n",
        "\n",
        "Feature Views wrap feature computation logic and register it with the Feature Store for reuse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save features to a table (Feature View source)\n",
        "email_features_df.write.mode(\"overwrite\").save_as_table(\"COMPLIANCE_DEMO.ML.EMAIL_RISK_FEATURES\")\n",
        "print(\"✅ Saved features to COMPLIANCE_DEMO.ML.EMAIL_RISK_FEATURES\")\n",
        "\n",
        "# Register Feature View\n",
        "email_risk_fv = FeatureView(\n",
        "    name=\"EMAIL_RISK_FEATURES\",\n",
        "    entities=[email_entity],\n",
        "    feature_df=session.table(\"COMPLIANCE_DEMO.ML.EMAIL_RISK_FEATURES\"),\n",
        "    desc=\"Per-email risk signals from text analysis and metadata\"\n",
        ")\n",
        "\n",
        "email_risk_fv = fs.register_feature_view(\n",
        "    feature_view=email_risk_fv,\n",
        "    version=\"V1\",\n",
        "    block=True,\n",
        ")\n",
        "print(\"✅ Registered FeatureView: EMAIL_RISK_FEATURES/V1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Generate Training Dataset\n",
        "\n",
        "Use the Feature Store to create a point-in-time correct training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create training spine (list of entities to get features for)\n",
        "training_spine = session.sql(\"\"\"\n",
        "    SELECT \n",
        "        EMAIL_ID,\n",
        "        COMPLIANCE_LABEL AS LABEL\n",
        "    FROM COMPLIANCE_DEMO.EMAIL_SURVEILLANCE.EMAILS\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Training spine has {training_spine.count():,} records\")\n",
        "\n",
        "# Generate training dataset with features\n",
        "training_dataset = fs.generate_dataset(\n",
        "    name=\"EMAIL_COMPLIANCE_TRAINING\",\n",
        "    spine_df=training_spine,\n",
        "    features=[email_risk_fv],\n",
        "    output_type=\"table\",\n",
        "    desc=\"Training dataset for email compliance classification\"\n",
        ")\n",
        "\n",
        "print(\"✅ Generated training dataset\")\n",
        "print(f\"Dataset: {training_dataset.fully_qualified_name()}\")\n",
        "\n",
        "# Preview the dataset\n",
        "training_dataset.read.df().show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "**What we built:**\n",
        "- Custom Python UDFs for text analysis (urgency, secrecy detection)\n",
        "- Feature computation pipeline for compliance risk signals\n",
        "- Registered Feature View in the Feature Store\n",
        "- Generated training dataset for model training\n",
        "\n",
        "**Features created:**\n",
        "| Feature | Type | Description |\n",
        "|---------|------|-------------|\n",
        "| URGENCY_SCORE | INT | Count of urgent keywords (0-6) |\n",
        "| SECRECY_SCORE | INT | Count of secrecy phrases (0-6) |\n",
        "| TOTAL_RISK_SCORE | INT | Combined risk score |\n",
        "| BODY_LENGTH | INT | Email body length |\n",
        "| IS_CROSS_DEPT | INT | 1 if cross-department |\n",
        "| IS_BARRIER_CROSSING | INT | 1 if Research↔Trading |\n",
        "| IS_AFTER_HOURS | INT | 1 if sent outside 8am-6pm |\n",
        "\n",
        "**Next:** In notebook 03, we'll train an XGBoost classifier using these features and register it in the Model Registry."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
