{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer 2: ML Classification with Snowflake Model Registry\n",
    "\n",
    "### What We're Building:\n",
    "- **XGBoost Classifier** trained on relative semantic risk scores\n",
    "- **Model Registry** - Version-controlled, auditable ML models\n",
    "- **Feature Store → Model lineage** - Full traceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import col\n",
    "from snowflake.ml.feature_store import FeatureStore\n",
    "from snowflake.ml.registry import Registry\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "\n",
    "session = Session.builder.getOrCreate()\n",
    "session.use_warehouse('COMPLIANCE_DEMO_WH')\n",
    "session.use_database('COMPLIANCE_DEMO')\n",
    "session.use_schema('ML')\n",
    "\n",
    "print(\"Layer 2: Training ML model on relative risk scores...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Features from Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FeatureStore(\n",
    "    session=session,\n",
    "    database=\"COMPLIANCE_DEMO\",\n",
    "    name=\"ML\",\n",
    "    default_warehouse=\"COMPLIANCE_DEMO_WH\"\n",
    ")\n",
    "\n",
    "semantic_fv = fs.get_feature_view(\"EMAIL_SEMANTIC_FEATURES\", \"V1\")\n",
    "print(f\"Loaded Feature View: {semantic_fv.name}/V1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = session.table('COMPLIANCE_DEMO.ML.EMAIL_SEMANTIC_FEATURES')\n",
    "\n",
    "print(f\"Total samples: {features_df.count():,}\")\n",
    "print(f\"Violation rate: {features_df.filter(col('IS_VIOLATION') == 1).count() / features_df.count() * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Training Data\n",
    "\n",
    "Features are **relative risk scores**: negative = normal, positive = risky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    'BASELINE_SIMILARITY',\n",
    "    'MNPI_RISK_SCORE', \n",
    "    'CONFIDENTIALITY_RISK_SCORE', \n",
    "    'PERSONAL_TRADING_RISK_SCORE',\n",
    "    'INFO_BARRIER_RISK_SCORE',\n",
    "    'CROSS_BARRIER_FLAG'\n",
    "]\n",
    "\n",
    "print(\"Features (semantic risk scores):\")\n",
    "for f in feature_cols:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "train_df, test_df = features_df.random_split([0.8, 0.2], seed=42)\n",
    "print(f\"\\nTrain: {train_df.count():,}, Test: {test_df.count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    input_cols=feature_cols,\n",
    "    label_cols=['IS_VIOLATION'],\n",
    "    output_cols=['PREDICTED_VIOLATION'],\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1\n",
    ")\n",
    "\n",
    "print(\"Training XGBoost on semantic risk scores...\")\n",
    "xgb_model.fit(train_df)\n",
    "print(\"Model trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "predictions = xgb_model.predict(test_df)\n",
    "pred_pd = predictions.to_pandas()\n",
    "\n",
    "accuracy = accuracy_score(pred_pd['IS_VIOLATION'], pred_pd['PREDICTED_VIOLATION'])\n",
    "precision = precision_score(pred_pd['IS_VIOLATION'], pred_pd['PREDICTED_VIOLATION'])\n",
    "recall = recall_score(pred_pd['IS_VIOLATION'], pred_pd['PREDICTED_VIOLATION'])\n",
    "f1 = f1_score(pred_pd['IS_VIOLATION'], pred_pd['PREDICTED_VIOLATION'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE ON TEST SET\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAccuracy:  {accuracy*100:.1f}%\")\n",
    "print(f\"Precision: {precision*100:.1f}%\")\n",
    "print(f\"Recall:    {recall*100:.1f}%\")\n",
    "print(f\"F1 Score:  {f1*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Register Model in Snowflake Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = Registry(session=session, database_name='COMPLIANCE_DEMO', schema_name='ML')\n",
    "\n",
    "try:\n",
    "    reg.delete_model('EMAIL_COMPLIANCE_CLASSIFIER')\n",
    "    print(\"Deleted existing model\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.ml.model import task as model_task\n",
    "\n",
    "model_version = reg.log_model(\n",
    "    model=xgb_model,\n",
    "    model_name='EMAIL_COMPLIANCE_CLASSIFIER',\n",
    "    version_name='V1',\n",
    "    conda_dependencies=['xgboost', 'scikit-learn'],\n",
    "    metrics={\n",
    "        'accuracy': float(accuracy),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'f1_score': float(f1),\n",
    "        'training_samples': int(train_df.count()),\n",
    "        'test_samples': int(test_df.count())\n",
    "    },\n",
    "    sample_input_data=train_df.select(*feature_cols).limit(100),\n",
    "    task=model_task.Task.TABULAR_BINARY_CLASSIFICATION,\n",
    "    comment='XGBoost on relative semantic risk scores (risk - baseline similarity)'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL REGISTERED IN SNOWFLAKE MODEL REGISTRY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModel: EMAIL_COMPLIANCE_CLASSIFIER/V1\")\n",
    "print(f\"Features: {feature_cols}\")\n",
    "print(f\"\\nMetrics stored in registry for audit trail.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run Inference at Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "all_emails_df = session.table('COMPLIANCE_DEMO.ML.EMAIL_SEMANTIC_FEATURES')\n",
    "\n",
    "start = time.time()\n",
    "scored_df = xgb_model.predict_proba(all_emails_df)\n",
    "scored_df.write.mode('overwrite').save_as_table('MODEL_PREDICTIONS_RAW')\n",
    "elapsed = time.time() - start\n",
    "\n",
    "count = session.sql('SELECT COUNT(*) as cnt FROM MODEL_PREDICTIONS_RAW').collect()[0]['CNT']\n",
    "print(f\"\\nScored {count:,} emails in {elapsed:.1f} seconds (with probabilities)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE MODEL_PREDICTIONS_V1 AS\n",
    "SELECT \n",
    "    *,\n",
    "    PREDICT_PROBA_1 as VIOLATION_PROBABILITY,\n",
    "    CASE \n",
    "        WHEN PREDICT_PROBA_1 >= 0.7 THEN 'HIGH_RISK'\n",
    "        WHEN PREDICT_PROBA_1 <= 0.3 THEN 'LOW_RISK'\n",
    "        ELSE 'NEEDS_REVIEW'\n",
    "    END as ML_DECISION\n",
    "FROM MODEL_PREDICTIONS_RAW\n",
    "\"\"\").collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"THREE-WAY ML CLASSIFICATION\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n  HIGH_RISK (prob >= 0.7):    Auto-escalate to compliance\")\n",
    "print(\"  NEEDS_REVIEW (0.3-0.7):     Send to LLM for deep analysis\")\n",
    "print(\"  LOW_RISK (prob <= 0.3):     Auto-clear\")\n",
    "\n",
    "session.sql(\"\"\"\n",
    "SELECT \n",
    "    ML_DECISION,\n",
    "    COUNT(*) as EMAIL_COUNT,\n",
    "    ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 1) as PCT,\n",
    "    SUM(IS_VIOLATION) as ACTUAL_VIOLATIONS,\n",
    "    ROUND(SUM(IS_VIOLATION) * 100.0 / COUNT(*), 1) as VIOLATION_RATE\n",
    "FROM MODEL_PREDICTIONS_V1\n",
    "GROUP BY 1\n",
    "ORDER BY VIOLATION_RATE DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why This Approach Works\n",
    "\n",
    "**ML on semantic features beats keyword rules because:**\n",
    "\n",
    "1. **Captures meaning, not words** - \"Let's keep this quiet\" matches secrecy concept even without \"confidential\"\n",
    "2. **Hard to evade** - Violators can change vocabulary, but meaning still clusters near risk concepts\n",
    "3. **Learns combinations** - XGBoost finds complex patterns (high secrecy + high urgency = very risky)\n",
    "4. **Relative scoring** - Normalizes against baseline business language\n",
    "\n",
    "**Limitation:** ML alone can't understand nuance or context. That's where LLMs come in (next layer).\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Add LLM for nuanced analysis →"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
